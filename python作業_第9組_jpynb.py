# -*- coding: utf-8 -*-
"""Python作業_第9組.jpynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Q5YfUBEnvbaedDI_j2nL0An_58dWuaW
"""

#組員
#姓名:409351604吳祐震、409351537林柏丞、409351484詹凱翔

#1請將「imdb_top_1000.xlsx」檔案存到你的Google雲端硬碟中，並分享檔案權限的方式讀取檔案中『Data』工作表中的資料，並命名為imdb1000資料集。(10%)

import pandas as pd
data = pd.read_excel('/content/drive/MyDrive/imdb_top_1000.xlsx')

#2請將imdb1000中欄位名稱為「Series_Title」改成「電影片名」；「Runtime」改為「影片長度」並重新存回imdb1000 (5%)。

data.rename(columns={'Series_Title': '電影片名', 'Runtime': '影片長度'}, inplace=True)

#3請用info指令檢視資料集中變數是否符合「imdb_top_1000.xlsx」檔案中『變數定義』所認定之定義；若不是，請將該變數轉型成適當的資料型別(10%)。

data.info()
data['Released_Year'] = data['Released_Year'].astype(object)

#4請將imdb1000中有遺失值的列刪除，另存成imdb_drop(5%)。

imdb_drop =data.dropna()
imdb_drop['Gross'] = imdb_drop['Gross'].str.replace(',','').astype(int)
imdb_drop.info()
imdb_drop.to_excel('imdb_drop.xlsx', index=False)

#5請用「if…elif…elif…else…判斷式」將imdb_drop中「IMDB_Rating」重新定義一個變數為『評等』存回imdb_drop這個資料集內，變數定義如下：(10%)
'''
A   >= 9.0
B   < 9.0 and >= 8.5
C   <8.5 and >= 8.0
D   <8.0
'''

def rating_category(rating):
  if rating >= 9:
    return "A"
  elif rating >= 8:
    return "B"
  elif rating >= 7:
    return "C"
  else:
    return "D"

imdb_drop['評等'] = imdb_drop['IMDB_Rating'].apply(rating_category)

#6請將imdb_drop中的「電影片名」定義成index並重新存回imdb_drop (5%)。

imdb_drop = imdb_drop.set_index("電影片名")

imdb_drop.head()

#7請將imdb_drop中「影片長度」、「IMDB_Rating」、「Meta_score」、「No_of_Votes」、「Gross」5個欄位資料另存為imdb_numeric資料集(5%)。

imdb_numeric = imdb_drop[["影片長度", "IMDB_Rating", "Meta_score", "No_of_Votes", "Gross"]]

#8計算imdb_numeric所有欄位的平均數、標準差、最大值、最小值，以及變數間的共變異數及相關係數矩陣(10%)。

imdb_numeric.head()

imdb_numeric.describe()

imdb_numeric.cov()

imdb_numeric.corr()

#9請將imdb_drop中「評等」另存成imdb_rate的資料集(5%)。

imdb_rate = imdb_drop["評等"]

imdb_rate.head()

#10請將imdb_rate及imdb_numeric兩個資料集進行欄位合併成imdb_merge(5%)。

imdb_merge = pd.merge(imdb_rate, imdb_numeric, left_index=True, right_index=True)

imdb_merge.head()

#11以imdb_merge中「評等」進行資料分組，分別計算其「影片長度」、「IMDB_Rating」、「Meta_score」、「No_of_Votes」、「Gross」5個變數的平均數、個數(10%)。

grouped_data = imdb_merge.groupby("評等")

average_values = grouped_data.mean()
count_values = grouped_data.count()

print("Average values per rating:")
print(average_values[["影片長度", "IMDB_Rating", "Meta_score", "No_of_Votes", "Gross"]])

print("\nCount of movies per rating:")
print(count_values[["影片長度", "IMDB_Rating", "Meta_score", "No_of_Votes", "Gross"]])


#12請以imdb_drop中「Certificate」項目的次數分配表繪製圓餅圖，並命名該圖表的title為『認證項目圓餅圖』(10%)。

import matplotlib.pyplot as plt
certificate_counts = imdb_drop["Certificate"].value_counts()

labels = certificate_counts.index.to_list()
sizes = certificate_counts.to_list()

plt.figure(figsize=(10, 7))
plt.pie(sizes, labels=labels, autopct="%1.1f%%")
plt.title("認證項目圓餅圖")
plt.show()

#13請篩選imdb_drop中「Certificate」為U的項目，且欄位保留「Certificate」及「Meta_Score」2個變數，另存成imdb_U資料集(5%)。
imdb_U = imdb_drop[imdb_drop["Certificate"] == "U"][["Certificate", "Meta_score"]]

imdb_U.head()

#14請繪製imdb_U中「Meta_Score」變數的莖葉圖(5%)。
import numpy as np

meta_scores = imdb_U["Meta_score"].dropna()

stems = np.floor(meta_scores / 10).astype(int)
leaves = meta_scores % 10

print("Stem-and-Leaf Plot for Meta_Score:")
for stem, leaves_group in zip(stems, np.split(leaves, np.unique(stems, return_index=True)[1][1:])):
  print(f"{stem:2d} | {''.join(map(str, leaves_group))}")

#15請繪製imdb_drop中「No_of_Votes」的盒鬚圖（以「評等」進行分組）(10%)。
import matplotlib.pyplot as plt

grouped_data = imdb_drop.groupby("評等")

fig, ax = plt.subplots()

for rating, group_data in grouped_data:
  group_data["No_of_Votes"].plot.box(ax=ax, label=rating)

ax.set_title("No_of_Votes Boxplot by Rating")
ax.set_xlabel("Rating")
ax.set_ylabel("Number of Votes")

plt.show()


Dat1 = pd.read_csv("https://mopsfin.twse.com.tw/opendata/t187ap46_O_1.csv", encoding="big5")

Dat2 = pd.read_csv("https://mopsfin.twse.com.tw/opendata/t187ap46_L_1.csv", encoding="big5")

merged_data = pd.concat([Dat1, Dat2], axis=0)

merged_data.head()

#16請分別讀入以下兩個檔案，並分別命名為Dat1及Dat2，再將這兩個檔案上下合併(10%)。
import pandas as pd

Dat1 = pd.read_csv("https://mopsfin.twse.com.tw/opendata/t187ap46_O_1.csv", encoding="utf-8-sig")

Dat2 = pd.read_csv("https://mopsfin.twse.com.tw/opendata/t187ap46_L_1.csv", encoding="utf-8-sig")

merged_data = pd.concat([Dat1, Dat2], axis=0)

merged_data.head()

